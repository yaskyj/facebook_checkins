{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 s, sys: 693 ms, total: 2.04 s\n",
      "Wall time: 5.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import ml_metrics as metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cross_validation, ensemble, tree, preprocessing, neighbors, naive_bayes, svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "le = preprocessing.LabelEncoder()\n",
    "import xgboost as xgb\n",
    "from datetime import datetime, date\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pylab as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ids = []\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27 s, sys: 2.87 s, total: 29.9 s\n",
      "Wall time: 30.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  2.5 2.75 0.0 0.25 18883 4847\n",
      "All Good:  2.5 2.75 0.0 0.25 4847 4847\n",
      "Test:  2.5 2.75 0.25 0.5 20443 5955\n",
      "All Good:  2.5 2.75 0.25 0.5 5955 5955\n",
      "Test:  2.5 2.75 0.5 0.75 18816 5505\n",
      "All Good:  2.5 2.75 0.5 0.75 5505 5505\n",
      "Test:  2.5 2.75 0.75 1.0 18742 6115\n",
      "All Good:  2.5 2.75 0.75 1.0 6115 6115\n",
      "Test:  2.5 2.75 1.0 1.25 26607 8115\n",
      "All Good:  2.5 2.75 1.0 1.25 8115 8115\n",
      "Test:  2.5 2.75 1.25 1.5 21243 5308\n",
      "All Good:  2.5 2.75 1.25 1.5 5308 5308\n",
      "Test:  2.5 2.75 1.5 1.75 18581 5292\n",
      "All Good:  2.5 2.75 1.5 1.75 5292 5292\n",
      "Test:  2.5 2.75 1.75 2.0 14068 4201\n",
      "All Good:  2.5 2.75 1.75 2.0 4201 4201\n",
      "Test:  2.5 2.75 2.0 2.25 15907 5218\n",
      "All Good:  2.5 2.75 2.0 2.25 5218 5218\n",
      "Test:  2.5 2.75 2.25 2.5 21765 6225\n",
      "All Good:  2.5 2.75 2.25 2.5 6225 6225\n",
      "Test:  2.5 2.75 2.5 2.75 19639 5160\n",
      "All Good:  2.5 2.75 2.5 2.75 5160 5160\n",
      "Test:  2.5 2.75 2.75 3.0 24871 6507\n",
      "All Good:  2.5 2.75 2.75 3.0 6507 6507\n",
      "Test:  2.5 2.75 3.0 3.25 21078 5487\n",
      "All Good:  2.5 2.75 3.0 3.25 5487 5487\n",
      "Test:  2.5 2.75 3.25 3.5 17409 5028\n",
      "All Good:  2.5 2.75 3.25 3.5 5028 5028\n",
      "Test:  2.5 2.75 3.5 3.75 19467 5285\n",
      "All Good:  2.5 2.75 3.5 3.75 5285 5285\n",
      "Test:  2.5 2.75 3.75 4.0 20289 6545\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in np.arange(2.5,5,.25):\n",
    "    for r in np.arange(0,10,.25):\n",
    "        train_reduced = train[(train.x >= i) & (train.x <= (i + .25)) & (train.y >= r) & (train.y <= (r + .25))]\n",
    "        if i == 9.75 and r == 9.75:\n",
    "            test_reduced = test[(test.x >= i) & (test.x <= (i + .25)) & (test.y >= r) & (test.y <= (r + .25))]\n",
    "        elif i == 9.75:\n",
    "            test_reduced = test[(test.x >= i) & (test.x <= (i + .25)) & (test.y >= r) & (test.y < (r + .25))]\n",
    "        elif r == 9.75:\n",
    "            test_reduced = test[(test.x >= i) & (test.x < (i + .25)) & (test.y >= r) & (test.y <= (r + .25))]\n",
    "        else:\n",
    "            test_reduced = test[(test.x >= i) & (test.x < (i + .25)) & (test.y >= r) & (test.y < (r + .25))]\n",
    "#         small_counts = train_reduced['place_id'].value_counts()\n",
    "#         print 'Test: ',i, (i + .5), r, (r + .5), len(train_reduced[train_reduced['place_id'].isin(small_counts[small_counts > 100].index)]), len(test_reduced)\n",
    "        print 'Test: ',i, (i + .25), r, (r + .25), len(train_reduced), len(test_reduced)\n",
    "#         train_reduced['day_number'] = ((train_reduced['time']/60)//24).astype(int)\n",
    "        train_reduced['seconds'] = (train_reduced['time'] * 60)\n",
    "        train_reduced['date_time'] = pd.to_datetime(train_reduced['seconds'],unit='s')\n",
    "        train_reduced['hour'] = train_reduced['date_time'].dt.hour\n",
    "        train_reduced['day'] = train_reduced['date_time'].dt.day\n",
    "        train_reduced['dow'] = train_reduced['date_time'].dt.dayofweek\n",
    "#         test_reduced['day_number'] = ((test_reduced['time']/60)//24).astype(int)\n",
    "        test_reduced['seconds'] = (test_reduced['time'] * 60)\n",
    "        test_reduced['date_time'] = pd.to_datetime(test_reduced['seconds'],unit='s')\n",
    "        test_reduced['hour'] = test_reduced['date_time'].dt.hour\n",
    "        test_reduced['day'] = test_reduced['date_time'].dt.day\n",
    "        test_reduced['dow'] = test_reduced['date_time'].dt.dayofweek\n",
    "        features = [c for c in train_reduced.columns if c in ['x', 'y', 'accuracy', 'hour', 'day', 'dow']]\n",
    "#         bayes = naive_bayes.GaussianNB().fit(train_reduced[features], train_reduced['place_id'])\n",
    "        forest = ensemble.RandomForestClassifier(n_estimators=20, n_jobs=-1).fit(train_reduced[features], train_reduced['place_id'])\n",
    "#         forest = ensemble.RandomForestClassifier(n_estimators=20, n_jobs=-1).fit(train_reduced[train_reduced['place_id'].isin(small_counts[small_counts > 100].index)][features], train_reduced[train_reduced['place_id'].isin(small_counts[small_counts > 100].index)]['place_id'])\n",
    "        probs = pd.DataFrame(forest.predict_proba(test_reduced[features]))\n",
    "#         probs.columns = np.unique(train_reduced[train_reduced['place_id'].isin(small_counts[small_counts > 100].index)]['place_id'].values)\n",
    "        probs.columns = np.unique(train_reduced['place_id'].sort_values().values)\n",
    "        preds = pd.DataFrame([list([p.sort_values(ascending=False)[:3].index.values]) for x,p in probs.iterrows()])\n",
    "        #pred = clf_rf.predict(test_reduced[features])\n",
    "        print 'All Good: ',i, (i + .25), r, (r + .25), len(test_reduced['row_id']), len(preds)\n",
    "        ids.append(list(test_reduced['row_id'].values))\n",
    "        predictions.append(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(ids), len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ids = [val for sublist in ids for val in sublist]\n",
    "predictions = [val for sublist in predictions for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(ids), len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "submission = pd.DataFrame()\n",
    "submission['row_id'] = ids\n",
    "submission['place_id'] = [' '.join(str(x) for x in y) for y in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "submission.to_csv('submissions/submission-2.5-5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "submission_1 = pd.read_csv('submissions/submission-0-2.5.csv')\n",
    "submission_2 = pd.read_csv('submissions/submission-2.5-5.csv')\n",
    "submission_3 = pd.read_csv('submissions/submission-5-7.5.csv')\n",
    "submission_4 = pd.read_csv('submissions/submission-7.5-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "submission_concat = pd.concat([submission_1,submission_2,submission_3,submission_4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "submission_concat.sort_values('row_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print len(test), len(submission_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "submission_concat.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#train_reduced = train[~train['place_id'].isin(counts[counts < 800].index)]\n",
    "train_reduced = train[(train.x >= 4.5) & (train.x < 4.75) & (train.y >= 4.5) & (train.y < 4.75)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_reduced['day_number'] = ((train_reduced['time']/60)//24).astype(int)\n",
    "train_reduced['seconds'] = (train_reduced['time'] * 60)\n",
    "train_reduced['date_time'] = pd.to_datetime(train_reduced['seconds'],unit='s')\n",
    "train_reduced['hour'] = train_reduced['date_time'].dt.hour\n",
    "train_reduced['day'] = train_reduced['date_time'].dt.day\n",
    "train_reduced['dow'] = train_reduced['date_time'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_reduced['date_time'].min(), train_reduced['date_time'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [12,9]\n",
    "plt.hist(train_reduced.day_number, bins=100, histtype = 'step')\n",
    "plt.autoscale(enable=True, axis='both', tight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [12,9]\n",
    "plt.hist(train_reduced.dow, bins=7)\n",
    "plt.autoscale(enable=True, axis='both', tight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [12,9]\n",
    "plt.hist(train_reduced.hour, bins=24)\n",
    "plt.autoscale(enable=True, axis='both', tight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [c for c in train_reduced.columns if c in ['x', 'y', 'accuracy', 'hour', 'day', 'dow']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [12,9]\n",
    "plt.scatter(train_reduced.x,train_reduced.y, c=train_reduced.place_id)\n",
    "plt.autoscale(enable=True, axis='both', tight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "small_counts = train_reduced['place_id'].value_counts()\n",
    "small_trainz = train_reduced[train_reduced['place_id'].isin(small_counts[small_counts > 100].index)]\n",
    "print len(small_trainz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "small_counts = train_reduced['place_id'].value_counts()\n",
    "small_trainz = train_reduced[train_reduced['place_id'].isin(small_counts[small_counts > 600].index)]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(small_trainz.x, small_trainz.y, zs=small_trainz.hour, zdir='z', s=20, c=small_trainz.place_id, depthshade=True)\n",
    "ax.scatter(train_reduced.x, train_reduced.y, zs=train_reduced.hour, zdir='z', s=20, c=train_reduced.place_id, depthshade=True)\n",
    "plt.autoscale(enable=True, axis='both', tight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(train_reduced[features], train_reduced['place_id'], test_size=0.70)\n",
    "# features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features_train, labels_train, test_size=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# neigh = neighbors.KNeighborsClassifier(weights='distance', n_jobs=-1).fit(features_train, labels_train)\n",
    "# forest = ensemble.RandomForestClassifier(n_estimators=20, n_jobs=-1).fit(features_train, labels_train)\n",
    "# bayes = naive_bayes.GaussianNB().fit(features_train, labels_train)\n",
    "boost = xgb.XGBClassifier(learning_rate=1,\n",
    "                          n_estimators=100,\n",
    "                          max_depth=5,\n",
    "                          min_child_weight=1,\n",
    "                          gamma=0,\n",
    "                          subsample=0.8,\n",
    "                          colsample_bytree=0.8,\n",
    "                          nthread=4,\n",
    "                          scale_pos_weight=1,\n",
    "                          seed=27,\n",
    "                          objective='multi:softprob').fit(features_train, labels_train)\n",
    "#  learning_rate = 1,\n",
    "#  max_depth=5,\n",
    "#  min_child_weight=1,\n",
    "#  gamma=0,\n",
    "#  subsample=0.8,\n",
    "#  colsample_bytree=0.8,\n",
    "#  objective= 'multi:softprob',\n",
    "#  nthread=4,\n",
    "#  scale_pos_weight=1,\n",
    "#  seed=27).fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "probs = pd.DataFrame(boost.predict_proba(features_test))\n",
    "probs.columns = np.unique(labels_train.sort_values().values)\n",
    "#probs.columns = np.unique(labels_train.values)\n",
    "preds = pd.DataFrame([list([r.sort_values(ascending=False)[:3].index.values]) for i,r in probs.iterrows()])\n",
    "print mapk([[l] for l in labels_test], preds[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "probs = pd.DataFrame(neigh.predict_proba(features_test))\n",
    "probs.columns = np.unique(labels_train.sort_values().values)\n",
    "#probs.columns = np.unique(labels_train.values)\n",
    "preds = pd.DataFrame([list([r.sort_values(ascending=False)[:3].index.values]) for i,r in probs.iterrows()])\n",
    "print mapk([[l] for l in labels_test], preds[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "probs = pd.DataFrame(forest.predict_proba(features_test))\n",
    "probs.columns = np.unique(labels_train.sort_values().values)\n",
    "#probs.columns = np.unique(labels_train.values)\n",
    "preds = pd.DataFrame([list([r.sort_values(ascending=False)[:3].index.values]) for i,r in probs.iterrows()])\n",
    "print mapk([[l] for l in labels_test], preds[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "probs = pd.DataFrame(bayes.predict_proba(features_test))\n",
    "probs.columns = np.unique(labels_train.sort_values().values)\n",
    "#probs.columns = np.unique(labels_train.values)\n",
    "preds = pd.DataFrame([list([r.sort_values(ascending=False)[:3].index.values]) for i,r in probs.iterrows()])\n",
    "print mapk([[l] for l in labels_test], preds[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
